{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2g9Hvm5jQvQ"
      },
      "source": [
        "# Deep Learning - Assigment 1\n",
        "\n",
        "### Group Number: 22\n",
        "\n",
        "### Teammates:\n",
        "1. **Mahshid Jafar Tajrishi**\n",
        "2. **Bar Melinarskiy**\n",
        "3. **Cis van Aken**\n",
        "4. **Simon van Klompenburg**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hello world!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ioA8A13jfIH",
        "outputId": "aacf198a-dab1-4419-f75f-23394d0f18ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTd51yRGjQvS"
      },
      "source": [
        "## Imports entire notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keHYaI-BifsE",
        "outputId": "e8376374-b87f-4ca4-fc04-32258910c357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Google Colab\n"
          ]
        }
      ],
      "source": [
        "# Helper function to check if the code is running in Google Colab\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# Usage\n",
        "if is_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "else:\n",
        "    print(\"Not running in Google Colab\")\n",
        "\n",
        "\n",
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast  # Add these imports for mixed precision training\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import zipfile\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GaGn3ZUZkti"
      },
      "source": [
        "## Global Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UF3472WxZkti"
      },
      "outputs": [],
      "source": [
        "# Path to the zip file\n",
        "data_dir = \"./Data\"\n",
        "data_path = f\"{data_dir}/Xtrain.mat\"\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set pandas display options to show all columns\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXX68RzaZkte",
        "outputId": "932d3083-a692-4f76-eb05-9d70ec7fbaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "90300\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)  # Should match CUDA 12.5\n",
        "print(torch.backends.cudnn.version())  # Should return a version, not None\n",
        "print(torch.cuda.is_available())  # Should return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24BC61sMoWgx",
        "outputId": "eb055c98-382d-461c-b659-501f95a4e433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ],
      "source": [
        "# If we are in colab and we need to mount the drive\n",
        "if is_colab():\n",
        "  from google.colab import drive\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')\n",
        "  print(\"Google Drive mounted successfully.\")\n",
        "  data_path = f\"/content/drive/MyDrive/{data_path}\"\n",
        "else:\n",
        "  print(\"Not in Google Colab.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ9g28e1jQvW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTe6RjJejQvW",
        "outputId": "5271569d-a167-4e45-d5d5-a13bca63a1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Xtrain: (1000, 1)\n",
            "First 10 rows of Xtrain:\n",
            "[[ 86]\n",
            " [141]\n",
            " [ 95]\n",
            " [ 41]\n",
            " [ 22]\n",
            " [ 21]\n",
            " [ 32]\n",
            " [ 72]\n",
            " [138]\n",
            " [111]]\n",
            "Xtrain as a PyTorch tensor: torch.Size([1000, 1])\n"
          ]
        }
      ],
      "source": [
        "train_dataset = loadmat(data_path)\n",
        "Xtrain = train_dataset['Xtrain']\n",
        "# Check the shape of the data\n",
        "print(\"Shape of Xtrain:\", Xtrain.shape)\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(\"First 10 rows of Xtrain:\")\n",
        "print(Xtrain[:10])\n",
        "\n",
        "# Convert to a PyTorch tensor if needed\n",
        "Xtrain_tensor = torch.tensor(Xtrain, dtype=torch.float32, device=device)\n",
        "print(\"Xtrain as a PyTorch tensor:\", Xtrain_tensor.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ExplainableAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}